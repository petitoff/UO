# Ponowne obliczenie dokładności dla klasyfikatora Bayesa
nb_predictions_factor <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
accuracy_bayes <- postResample(nb_predictions_factor, as.factor(test_data$V14))[1]
# Sprawdzenie, czy wartość dokładności jest teraz dostępna
print(accuracy_bayes)
# Aktualizacja ramki danych accuracy_data z nową wartością
accuracy_data$Accuracy[1] <- accuracy_bayes
# Ponowne wygenerowanie wykresu
ggplot(accuracy_data, aes(x = Model, y = Accuracy)) +
geom_bar(stat = "identity", position = "dodge") +
ylim(0, 1)  # Dodanie limitu osi Y, jeśli dokładność jest w skali od 0 do 1
# Ponowne obliczenie dokładności dla klasyfikatora Bayesa
nb_predictions_factor <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
accuracy_bayes <- postResample(nb_predictions_factor, as.factor(test_data$V14))[1]
# Sprawdzenie, czy wartość dokładności jest teraz dostępna
print(accuracy_bayes)
# Aktualizacja ramki danych accuracy_data z nową wartością
accuracy_data$Accuracy[1] <- accuracy_bayes
# Ponowne wygenerowanie wykresu
ggplot(accuracy_data, aes(x = Model, y = Accuracy)) +
geom_bar(stat = "identity", position = "dodge") +
ylim(0, 1)  # Dodanie limitu osi Y, jeśli dokładność jest w skali od 0 do 1
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data[, ncol(data)], p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
nb_model <- naiveBayes(as.factor(V14) ~ ., data = train_data)
print(nb_model)
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# d) Dokładność klasyfikacji i współczynnik błędu
accuracy <- sum(nb_predictions == test_data$V14) / nrow(test_data)
error_rate <- 1 - accuracy
print(accuracy)
print(error_rate)
# e) Cztery modele SVM
svm_radial <- svm(as.factor(V14) ~ ., data = train_data, method = "C-classification", kernel = "radial")
svm_linear <- svm(as.factor(V14) ~ ., data = train_data, method = "C-classification", kernel = "linear")
svm_polynomial <- svm(as.factor(V14) ~ ., data = train_data, method = "C-classification", kernel = "polynomial")
svm_sigmoid <- svm(as.factor(V14) ~ ., data = train_data, method = "C-classification", kernel = "sigmoid")
# f) Parametry i liczba wektorów nośnych dla każdego modelu
summary(svm_radial)
summary(svm_linear)
summary(svm_polynomial)
summary(svm_sigmoid)
# g) Klasyfikacja zbioru testowego dla modeli SVM
svm_radial_pred <- predict(svm_radial, test_data)
svm_linear_pred <- predict(svm_linear, test_data)
svm_polynomial_pred <- predict(svm_polynomial, test_data)
svm_sigmoid_pred <- predict(svm_sigmoid, test_data)
# h) Macierze błędów i dokładność dla każdego modelu SVM
# Konwersja przewidywań do tego samego typu i poziomów co oryginalna zmienna celu
svm_radial_pred_factor <- factor(svm_radial_pred, levels = levels(as.factor(test_data$V14)))
svm_linear_pred_factor <- factor(svm_linear_pred, levels = levels(as.factor(test_data$V14)))
svm_polynomial_pred_factor <- factor(svm_polynomial_pred, levels = levels(as.factor(test_data$V14)))
svm_sigmoid_pred_factor <- factor(svm_sigmoid_pred, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(svm_radial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_linear_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_polynomial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_sigmoid_pred_factor, as.factor(test_data$V14))
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data[, ncol(data)], p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
nb_model <- naiveBayes(as.factor(V14) ~ ., data = train_data)
print(nb_model)
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data[, ncol(data)], p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
nb_model <- naiveBayes(as.factor(V14) ~ ., data = train_data)
print(nb_model)
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data[, ncol(data)], p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data[, ncol(data)], p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
nb_model <- naiveBayes(as.factor(V14) ~ ., data = train_data)
# print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data$V14, p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
library(e1071)
nb_model <- naiveBayes(V14 ~ ., data = train_data)
print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
confusionMatrix(nb_predictions, test_data$V14)
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data$V14, p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
library(e1071)
nb_model <- naiveBayes(V14 ~ ., data = train_data)
print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# d) Dokładność klasyfikacji i współczynnik błędu
accuracy <- sum(nb_predictions == test_data$V14) / nrow(test_data)
error_rate <- 1 - accuracy
print(accuracy)
print(error_rate)
# j) Wykres Słupkowy Dokładności
accuracy_values <- c(accuracy_nb, accuracy_radial, accuracy_linear, accuracy_polynomial, accuracy_sigmoid)
# j) Wykres Słupkowy Dokładności
# Obliczenie dokładności dla każdego modelu
accuracy_nb <- sum(nb_predictions == test_data$V14) / nrow(test_data)
accuracy_radial <- sum(predictions_radial == test_data$V14) / nrow(test_data)
# j) Wykres Słupkowy Dokładności
# Obliczenie dokładności dla każdego modelu
accuracy_nb <- sum(nb_predictions == test_data$V14) / nrow(test_data)
accuracy_radial <- sum(predictions_radial == test_data$V14) / nrow(test_data)
# j) Wykres Słupkowy Dokładności
predictions_radial <- predict(svm_radial, test_data_scaled[, -ncol(test_data_scaled)])
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data$V14, p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
library(e1071)
nb_model <- naiveBayes(V14 ~ ., data = train_data)
print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# d) Dokładność klasyfikacji i współczynnik błędu
accuracy <- sum(nb_predictions == test_data$V14) / nrow(test_data)
error_rate <- 1 - accuracy
print(accuracy)
print(error_rate)
# e) Cztery modele SVM
library(kernlab)
# Przygotowanie danych (standaryzacja)
train_data_scaled <- scale(train_data[, -ncol(train_data)])
test_data_scaled <- scale(test_data[, -ncol(test_data)])
# SVM z różnymi jądrami
svm_radial <- ksvm(V14 ~ ., data = train_data, kernel = "rbfdot")
svm_linear <- ksvm(V14 ~ ., data = train_data, kernel = "vanilladot")
svm_polynomial <- ksvm(V14 ~ ., data = train_data, kernel = "polydot")
svm_sigmoid <- ksvm(V14 ~ ., data = train_data, kernel = "tanhdot")
# f) Parametry i liczba wektorów nośnych dla każdego modelu
summary(svm_radial)
summary(svm_linear)
summary(svm_polynomial)
summary(svm_sigmoid)
# g) Klasyfikacja zbioru testowego dla modeli SVM
svm_radial_pred <- predict(svm_radial, test_data)
svm_linear_pred <- predict(svm_linear, test_data)
svm_polynomial_pred <- predict(svm_polynomial, test_data)
svm_sigmoid_pred <- predict(svm_sigmoid, test_data)
# h) Macierze błędów i dokładność dla każdego modelu SVM
# Konwersja przewidywań do tego samego typu i poziomów co oryginalna zmienna celu
svm_radial_pred_factor <- factor(svm_radial_pred, levels = levels(as.factor(test_data$V14)))
svm_linear_pred_factor <- factor(svm_linear_pred, levels = levels(as.factor(test_data$V14)))
svm_polynomial_pred_factor <- factor(svm_polynomial_pred, levels = levels(as.factor(test_data$V14)))
svm_sigmoid_pred_factor <- factor(svm_sigmoid_pred, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(svm_radial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_linear_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_polynomial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_sigmoid_pred_factor, as.factor(test_data$V14))
# j) Wykres Słupkowy Dokładności
predictions_radial <- predict(svm_radial, test_data_scaled[, -ncol(test_data_scaled)])
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data$V14, p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
library(e1071)
nb_model <- naiveBayes(V14 ~ ., data = train_data)
# print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# d) Dokładność klasyfikacji i współczynnik błędu
accuracy <- sum(nb_predictions == test_data$V14) / nrow(test_data)
error_rate <- 1 - accuracy
print(accuracy)
print(error_rate)
# e) Cztery modele SVM
library(kernlab)
# Przygotowanie danych (standaryzacja)
train_data_scaled <- scale(train_data[, -ncol(train_data)])
test_data_scaled <- scale(test_data[, -ncol(test_data)])
# SVM z różnymi jądrami
svm_radial <- ksvm(V14 ~ ., data = train_data, kernel = "rbfdot")
svm_linear <- ksvm(V14 ~ ., data = train_data, kernel = "vanilladot")
svm_polynomial <- ksvm(V14 ~ ., data = train_data, kernel = "polydot")
svm_sigmoid <- ksvm(V14 ~ ., data = train_data, kernel = "tanhdot")
# f) Parametry i liczba wektorów nośnych dla każdego modelu
summary(svm_radial)
summary(svm_linear)
summary(svm_polynomial)
summary(svm_sigmoid)
# g) Klasyfikacja zbioru testowego dla modeli SVM
svm_radial_pred <- predict(svm_radial, test_data)
svm_linear_pred <- predict(svm_linear, test_data)
svm_polynomial_pred <- predict(svm_polynomial, test_data)
svm_sigmoid_pred <- predict(svm_sigmoid, test_data)
# h) Macierze błędów i dokładność dla każdego modelu SVM
# Konwersja przewidywań do tego samego typu i poziomów co oryginalna zmienna celu
svm_radial_pred_factor <- factor(svm_radial_pred, levels = levels(as.factor(test_data$V14)))
svm_linear_pred_factor <- factor(svm_linear_pred, levels = levels(as.factor(test_data$V14)))
svm_polynomial_pred_factor <- factor(svm_polynomial_pred, levels = levels(as.factor(test_data$V14)))
svm_sigmoid_pred_factor <- factor(svm_sigmoid_pred, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(svm_radial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_linear_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_polynomial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_sigmoid_pred_factor, as.factor(test_data$V14))
# j) Wykres Słupkowy Dokładności
predictions_radial <- predict(svm_radial, test_data_scaled[, -ncol(test_data_scaled)])
# Użyj tych samych średnich i odchylenia standardowego z danych treningowych do przeskalowania danych testowych
test_data_scaled <- scale(test_data[, -ncol(test_data)], center = attr(train_data_scaled, "scaled:center"), scale = attr(train_data_scaled, "scaled:scale"))
# Wykonanie predykcji
predictions_radial <- predict(svm_radial, test_data_scaled[, -ncol(test_data_scaled)])
library(rpart)
library(rpart.plot)
library(rpart)
library(rpart.plot)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista11"
setwd(path)
# Wczytanie danych
wine <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Ustawienie ziarna dla reprodukowalności wyników
indeksy <- sample(1:nrow(wine), nrow(wine) * 0.7)
train_data <- wine[indeksy, ]
test_data <- wine[-indeksy, ]
# Budowa modelu drzewa decyzyjnego z ograniczeniem do 3 poziomów
tree_model <- rpart(V1 ~ ., data = train_data, method = "class", cp = 0, maxdepth = 3)
# Wyświetlenie podsumowania modelu
print(summary(tree_model))
# Rysowanie drzewa
rpart.plot(tree_model)
# Budowa modelu drzewa decyzyjnego bez ograniczenia liczby poziomów
full_tree_model <- rpart(V1 ~ ., data = train_data, method = "class", cp = 0)
# Klasyfikacja danych ze zbioru testowego
predictions <- predict(full_tree_model, test_data, type = "class")
# Macierz błędów, dokładność i % błędów
confusion_matrix <- table(test_data$V1, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
error_rate <- 1 - accuracy
print(confusion_matrix)
print(paste("Accuracy:", accuracy))
print(paste("Error rate:", error_rate))
library(rpart)
library(rpart.plot)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista11"
setwd(path)
# Wczytanie danych
wine <- read.csv('wine/wine.data', header = FALSE)
# Podział danych na zbiór treningowy i testowy
set.seed(123)  # Ustawienie ziarna dla reprodukowalności wyników
indeksy <- sample(1:nrow(wine), nrow(wine) * 0.7)
train_data <- wine[indeksy, ]
test_data <- wine[-indeksy, ]
# Budowa modelu drzewa decyzyjnego z ograniczeniem do 3 poziomów
tree_model <- rpart(V1 ~ ., data = train_data, method = "class", cp = 0, maxdepth = 3)
# Wyświetlenie podsumowania modelu
print(summary(tree_model))
# Rysowanie drzewa
rpart.plot(tree_model)
# Budowa modelu drzewa decyzyjnego bez ograniczenia liczby poziomów
full_tree_model <- rpart(V1 ~ ., data = train_data, method = "class", cp = 0)
# Klasyfikacja danych ze zbioru testowego
predictions <- predict(full_tree_model, test_data, type = "class")
# Macierz błędów, dokładność i % błędów
confusion_matrix <- table(test_data$V1, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
error_rate <- 1 - accuracy
print(confusion_matrix)
print(paste("Accuracy:", accuracy))
print(paste("Error rate:", error_rate))
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista12"
setwd(path)
# Wczytanie danych
wine <- read.csv('wine/wine.data', header = FALSE)
# Ustawienie ziarna losowości dla powtarzalności wyników
set.seed(123)
# Podział danych na zbiory treningowe i testowe
splitIndex <- createDataPartition(wine_data$V1, p = 0.65, list = FALSE)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista12"
setwd(path)
# Wczytanie danych
wine_data <- read.csv('wine/wine.data', header = FALSE)
# Ustawienie ziarna losowości dla powtarzalności wyników
set.seed(123)
# Podział danych na zbiory treningowe i testowe
splitIndex <- createDataPartition(wine_data$V1, p = 0.65, list = FALSE)
trainData <- wine_data[splitIndex,]
testData <- wine_data[-splitIndex,]
# Zadanie 2: Klasyfikacja metodami bagging, boosting i losowy las
# Wczytanie potrzebnych bibliotek
library(randomForest)
library(gbm)
library(adabag)
# Losowy las
rf_model <- randomForest(V1 ~ ., data=trainData)
rf_pred <- predict(rf_model, testData)
rf_confMat <- confusionMatrix(rf_pred, testData$V1)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista12"
setwd(path)
# Wczytanie danych
wine_data <- read.csv('wine/wine.data', header = FALSE)
# Ustawienie ziarna losowości dla powtarzalności wyników
set.seed(123)
# Podział danych na zbiory treningowe i testowe
splitIndex <- createDataPartition(wine_data$V1, p = 0.65, list = FALSE)
trainData <- wine_data[splitIndex,]
testData <- wine_data[-splitIndex,]
# Zadanie 2: Klasyfikacja metodami bagging, boosting i losowy las
# Wczytanie potrzebnych bibliotek
library(randomForest)
library(gbm)
library(adabag)
# Losowy las
rf_model <- randomForest(V1 ~ ., data=trainData)
rf_pred <- predict(rf_model, testData)
rf_confMat <- confusionMatrix(rf_pred, testData$V1)
# Wczytanie potrzebnych bibliotek
library(e1071)
library(caret)
library(ggplot2)
# Ustawienie ścieżki dostępu do danych
path <- "C:/Users/petit/Desktop/repos/UO/rok 3/Wprowadzenie do eksploracji danych/lista10"
setwd(path)
# Wczytanie danych
data <- read.csv('wine/wine.data', header = FALSE)
set.seed(123)  # Dla powtarzalności wyników
splitIndex <- createDataPartition(data$V14, p = .8, list = FALSE)
train_data <- data[splitIndex, ]
test_data <- data[-splitIndex, ]
# b) Naiwny klasyfikator Bayesowski
library(e1071)
nb_model <- naiveBayes(V14 ~ ., data = train_data)
# print(nb_model)
write.csv(nb_model$tables, file = "nb_model.csv")
# c) Klasyfikacja danych testowych i macierz błędów
nb_predictions <- predict(nb_model, test_data)
# Upewnienie się, że przewidywania mają te same poziomy co zmienna celu
nb_predictions <- factor(nb_predictions, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(nb_predictions, as.factor(test_data$V14))
# d) Dokładność klasyfikacji i współczynnik błędu
accuracy <- sum(nb_predictions == test_data$V14) / nrow(test_data)
error_rate <- 1 - accuracy
print(accuracy)
print(error_rate)
# e) Cztery modele SVM
library(kernlab)
# Przygotowanie danych (standaryzacja)
train_data_scaled <- scale(train_data[, -ncol(train_data)])
test_data_scaled <- scale(test_data[, -ncol(test_data)])
# SVM z różnymi jądrami
svm_radial <- ksvm(V14 ~ ., data = train_data, kernel = "rbfdot")
svm_linear <- ksvm(V14 ~ ., data = train_data, kernel = "vanilladot")
svm_polynomial <- ksvm(V14 ~ ., data = train_data, kernel = "polydot")
svm_sigmoid <- ksvm(V14 ~ ., data = train_data, kernel = "tanhdot")
# f) Parametry i liczba wektorów nośnych dla każdego modelu
summary(svm_radial)
summary(svm_linear)
summary(svm_polynomial)
summary(svm_sigmoid)
# g) Klasyfikacja zbioru testowego dla modeli SVM
svm_radial_pred <- predict(svm_radial, test_data)
svm_linear_pred <- predict(svm_linear, test_data)
svm_polynomial_pred <- predict(svm_polynomial, test_data)
svm_sigmoid_pred <- predict(svm_sigmoid, test_data)
# h) Macierze błędów i dokładność dla każdego modelu SVM
# Konwersja przewidywań do tego samego typu i poziomów co oryginalna zmienna celu
svm_radial_pred_factor <- factor(svm_radial_pred, levels = levels(as.factor(test_data$V14)))
svm_linear_pred_factor <- factor(svm_linear_pred, levels = levels(as.factor(test_data$V14)))
svm_polynomial_pred_factor <- factor(svm_polynomial_pred, levels = levels(as.factor(test_data$V14)))
svm_sigmoid_pred_factor <- factor(svm_sigmoid_pred, levels = levels(as.factor(test_data$V14)))
# Tworzenie macierzy błędów
confusionMatrix(svm_radial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_linear_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_polynomial_pred_factor, as.factor(test_data$V14))
confusionMatrix(svm_sigmoid_pred_factor, as.factor(test_data$V14))
# j) Wykres Słupkowy Dokładności
# Użyj tych samych średnich i odchylenia standardowego z danych treningowych do przeskalowania danych testowych
test_data_scaled <- scale(test_data[, -ncol(test_data)], center = attr(train_data_scaled, "scaled:center"), scale = attr(train_data_scaled, "scaled:scale"))
# Wykonanie predykcji
predictions_radial <- predict(svm_radial, test_data_scaled[, -ncol(test_data_scaled)])
